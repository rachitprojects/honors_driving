{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "isaferesnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachitprojects/honors_driving/blob/main/isaferesnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa1tPFf3CigG"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.activations import relu\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import layers as Layers\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# class ResBlock(Model):\n",
        "#     def __init__(self, channels, stride=1):\n",
        "#         super(ResBlock, self).__init__(name='ResBlock')\n",
        "#         self.flag = (stride != 1)\n",
        "#         self.conv1 = Conv2D(channels, 3, stride, padding='same')\n",
        "#         self.bn1 = BatchNormalization()\n",
        "#         self.conv2 = Conv2D(channels, 3, padding='same')\n",
        "#         self.bn2 = BatchNormalization()\n",
        "#         self.relu = ReLU()\n",
        "#         if self.flag:\n",
        "#             self.bn3 = BatchNormalization()\n",
        "#             self.conv3 = Conv2D(channels, 1, stride)\n",
        "\n",
        "#     def call(self, x):\n",
        "#         x1 = self.conv1(x)\n",
        "#         x1 = self.bn1(x1)\n",
        "#         x1 = self.relu(x1)\n",
        "#         x1 = self.conv2(x1)\n",
        "#         x1 = self.bn2(x1)\n",
        "#         if self.flag:\n",
        "#             x = self.conv3(x)\n",
        "#             x = self.bn3(x)\n",
        "#         x1 = Layers.add([x, x1])\n",
        "#         x1 = self.relu(x1)\n",
        "#         return x1\n",
        "\n",
        "\n",
        "# class ResNet34(Model):\n",
        "#     def __init__(self):\n",
        "#         super(ResNet34, self).__init__(name='ResNet34')\n",
        "#         self.conv1 = Conv2D(64, 7, 2, padding='same')\n",
        "#         self.bn = BatchNormalization()\n",
        "#         self.relu = ReLU()\n",
        "#         self.mp1 = MaxPooling2D(3, 2)\n",
        "\n",
        "#         self.conv2_1 = ResBlock(64)\n",
        "#         self.conv2_2 = ResBlock(64)\n",
        "#         self.conv2_3 = ResBlock(64)\n",
        "\n",
        "#         self.conv3_1 = ResBlock(128, 2)\n",
        "#         self.conv3_2 = ResBlock(128)\n",
        "#         self.conv3_3 = ResBlock(128)\n",
        "#         self.conv3_4 = ResBlock(128)\n",
        "\n",
        "#         self.conv4_1 = ResBlock(256, 2)\n",
        "#         self.conv4_2 = ResBlock(256)\n",
        "#         self.conv4_3 = ResBlock(256)\n",
        "#         self.conv4_4 = ResBlock(256)\n",
        "#         self.conv4_5 = ResBlock(256)\n",
        "#         self.conv4_6 = ResBlock(256)\n",
        "\n",
        "#         self.conv5_1 = ResBlock(512, 2)\n",
        "#         self.conv5_2 = ResBlock(512)\n",
        "#         self.conv5_3 = ResBlock(512)\n",
        "\n",
        "#         self.pool = GlobalAveragePooling2D()\n",
        "#         self.fc1 = Dense(512, activation='relu')\n",
        "#         self.dp1 = Dropout(0.5)\n",
        "#         self.fc2 = Dense(512, activation='relu')\n",
        "#         self.dp2 = Dropout(0.5)\n",
        "#         self.fc3 = Dense(9)\n",
        "\n",
        "#     def call(self, x):\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.bn(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.mp1(x)\n",
        "\n",
        "#         x = self.conv2_1(x)\n",
        "#         x = self.conv2_2(x)\n",
        "#         x = self.conv2_3(x)\n",
        "\n",
        "#         x = self.conv3_1(x)\n",
        "#         x = self.conv3_2(x)\n",
        "#         x = self.conv3_3(x)\n",
        "#         x = self.conv3_4(x)\n",
        "\n",
        "#         x = self.conv4_1(x)\n",
        "#         x = self.conv4_2(x)\n",
        "#         x = self.conv4_3(x)\n",
        "#         x = self.conv4_4(x)\n",
        "#         x = self.conv4_5(x)\n",
        "#         x = self.conv4_6(x)\n",
        "\n",
        "#         x = self.conv5_1(x)\n",
        "#         x = self.conv5_2(x)\n",
        "#         x = self.conv5_3(x)\n",
        "\n",
        "#         x = self.pool(x)\n",
        "#         x = self.fc1(x)\n",
        "#         x = self.dp1(x)\n",
        "#         x = self.fc2(x)\n",
        "#         x = self.dp2(x)\n",
        "#         x = self.fc3(x)\n",
        "#         return x\n",
        "\n",
        "\n",
        "# model = ResNet34()\n",
        "# model.build(input_shape=(1, 112, 112, 3))\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# from tensorflow import Tensor\n",
        "# from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
        "#                                     Add, AveragePooling2D, Flatten, Dense\n",
        "# from tensorflow.keras.models import Model\n",
        "\n",
        "# def relu_bn(inputs: Tensor) -> Tensor:\n",
        "#     relu = ReLU()(inputs)\n",
        "#     bn = BatchNormalization()(relu)\n",
        "#     return bn\n",
        "\n",
        "# def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
        "#     y = Conv2D(kernel_size=kernel_size,\n",
        "#                strides= (1 if not downsample else 2),\n",
        "#                filters=filters,\n",
        "#                padding=\"same\")(x)\n",
        "#     y = relu_bn(y)\n",
        "#     y = Conv2D(kernel_size=kernel_size,\n",
        "#                strides=1,\n",
        "#                filters=filters,\n",
        "#                padding=\"same\")(y)\n",
        "\n",
        "#     if downsample:\n",
        "#         x = Conv2D(kernel_size=1,\n",
        "#                    strides=2,\n",
        "#                    filters=filters,\n",
        "#                    padding=\"same\")(x)\n",
        "#     out = Add()([x, y])\n",
        "#     out = relu_bn(out)\n",
        "#     return out\n",
        "\n",
        "# def create_res_net():\n",
        "    \n",
        "#     inputs = Input(shape=(112, 112, 3))\n",
        "#     num_filters = 64\n",
        "    \n",
        "#     t = BatchNormalization()(inputs)\n",
        "#     t = Conv2D(kernel_size=3,\n",
        "#                strides=1,\n",
        "#                filters=num_filters,\n",
        "#                padding=\"same\")(t)\n",
        "#     t = relu_bn(t)\n",
        "    \n",
        "#     num_blocks_list = [2, 5, 5, 2]\n",
        "#     for i in range(len(num_blocks_list)):\n",
        "#         num_blocks = num_blocks_list[i]\n",
        "#         for j in range(num_blocks):\n",
        "#             t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
        "#         num_filters *= 2\n",
        "    \n",
        "#     t = AveragePooling2D(4)(t)\n",
        "#     t = Flatten()(t)\n",
        "#     outputs = Dense(9, activation='softmax')(t)\n",
        "    \n",
        "#     model = Model(inputs, outputs)\n",
        "\n",
        "#     model.compile(\n",
        "#         optimizer='adam',\n",
        "#         loss='categorical_crossentropy',\n",
        "#         metrics=['accuracy']\n",
        "#     )\n",
        "\n",
        "#     return model\n",
        "\n",
        "# model = create_res_net()\n",
        "\n",
        "\n",
        "# from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "# model = ResNet50(weights=None, input_shape=(112, 112, 3), classes=9)\n",
        "# model.compile(\n",
        "#         optimizer='adam',\n",
        "#         loss='categorical_crossentropy',\n",
        "#         metrics=['accuracy']\n",
        "#     )\n",
        "\n",
        "# def resnet_layer(inputs, num_filters = 16, kernel_size = 3, strides = 1, activation ='relu', batch_normalization = True, conv = Conv2D(num_filters,\n",
        "#                   kernel_size = kernel_size,\n",
        "#                   strides = strides,\n",
        "#                   padding ='same',\n",
        "#                   kernel_initializer ='he_normal',\n",
        "#                   kernel_regularizer = l2(1e-4)) )\n",
        "#     x = inputs\n",
        "#     if conv_first:\n",
        "#         x = conv(x)\n",
        "#         if batch_normalization:\n",
        "#             x = BatchNormalization()(x)\n",
        "#         if activation is not None:\n",
        "#             x = Activation(activation)(x)\n",
        "#     else:\n",
        "#         if batch_normalization:\n",
        "#             x = BatchNormalization()(x)\n",
        "#         if activation is not None:\n",
        "#             x = Activation(activation)(x)\n",
        "#         x = conv(x)\n",
        "#     return x\n",
        "\n",
        "# def resnet_v1(input_shape, depth, num_classes = 10):\n",
        "      \n",
        "#     if (depth - 2) % 6 != 0:\n",
        "#         raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])')\n",
        "#     # Start model definition.\n",
        "#     num_filters = 16\n",
        "#     num_res_blocks = int((depth - 2) / 6)\n",
        "  \n",
        "#     inputs = Input(shape = input_shape)\n",
        "#     x = resnet_layer(inputs = inputs)\n",
        "#     # Instantiate the stack of residual units\n",
        "#     for stack in range(3):\n",
        "#         for res_block in range(num_res_blocks):\n",
        "#             strides = 1\n",
        "#             if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "#                 strides = 2  # downsample\n",
        "#             y = resnet_layer(inputs = x,\n",
        "#                              num_filters = num_filters,\n",
        "#                              strides = strides)\n",
        "#             y = resnet_layer(inputs = y,\n",
        "#                              num_filters = num_filters,\n",
        "#                              activation = None)\n",
        "#             if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "#                 # linear projection residual shortcut connection to match\n",
        "#                 # changed dims\n",
        "#                 x = resnet_layer(inputs = x,\n",
        "#                                  num_filters = num_filters,\n",
        "#                                  kernel_size = 1,\n",
        "#                                  strides = strides,\n",
        "#                                  activation = None,\n",
        "#                                  batch_normalization = False)\n",
        "#             x = keras.layers.add([x, y])\n",
        "#             x = Activation('relu')(x)\n",
        "#         num_filters *= 2\n",
        "  \n",
        "#     # Add classifier on top.\n",
        "#     # v1 does not use BN after last shortcut connection-ReLU\n",
        "#     x = AveragePooling2D(pool_size = 8)(x)\n",
        "#     y = Flatten()(x)\n",
        "#     outputs = Dense(num_classes,\n",
        "#                     activation ='softmax',\n",
        "#                     kernel_initializer ='he_normal')(y)\n",
        "  \n",
        "#     # Instantiate model.\n",
        "#     model = Model(inputs = inputs, outputs = outputs)\n",
        "#     return model\n",
        "\n",
        "model = resnet_v1((112, 112, 3), 34, 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxhp6HOrBTMg",
        "outputId": "9e832e5c-f188-4198-9cab-7ee360702284"
      },
      "source": [
        "!pip install git+https://github.com/qubvel/classification_models.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/qubvel/classification_models.git\n",
            "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-7wf_rvh6\n",
            "  Running command git clone -q https://github.com/qubvel/classification_models.git /tmp/pip-req-build-7wf_rvh6\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Collecting keras_applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.5.2)\n",
            "Building wheels for collected packages: image-classifiers\n",
            "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-py3-none-any.whl size=20045 sha256=4a2aa3e2e7dfca84185c1b72678b7ce3c2b8d2da06a2a6d96701eaf04f550e3c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v5njxr0l/wheels/0b/96/56/27b17c903efc647c51e4f364bfc20aa67f8d3dccad63c4fb4e\n",
            "Successfully built image-classifiers\n",
            "Installing collected packages: keras-applications, image-classifiers\n",
            "Successfully installed image-classifiers-1.0.0 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHfB6gufBcEx",
        "outputId": "8a93b612-e23e-4f39-b937-e69891f0f7d5"
      },
      "source": [
        "import keras\n",
        "from classification_models.keras import Classifiers\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "n_classes = 9\n",
        "\n",
        "ResNet34, preprocess_input = Classifiers.get('resnet34')\n",
        "base_model = ResNet34(input_shape=(112,112,3), include_top=False) \n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "##### Added Monday Sep 6th\n",
        "# regularizer = keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
        "####\n",
        "output = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
        "model = keras.models.Model(inputs=[base_model.input], outputs=[output])\n",
        "# opt = SGD(lr=0.002, momentum=0.8)\n",
        "# model.compile(\n",
        "#         optimizer=opt,\n",
        "#         loss='categorical_crossentropy',\n",
        "#         metrics=['accuracy']\n",
        "#     )\n",
        "\n",
        "opt = SGD(lr=0.2, momentum=0.8)\n",
        "model.compile(\n",
        "        optimizer=opt,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqrwhZsk55M-"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zad_gLiSFJYc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gQoB7UsICXJ"
      },
      "source": [
        "# from keras.datasets import cifar10\n",
        "# (X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX0jTqs9IIR4"
      },
      "source": [
        "# import  matplotlib.pyplot as plt\n",
        "# plt.imshow(X_test[2])\n",
        "# print(y_test[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO6h9xOtIxgP"
      },
      "source": [
        "# from keras.utils import np_utils\n",
        "# y = np_utils.to_categorical([[1], [2], [3], [4], [5], [7], [5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrJD_Rop6N3W"
      },
      "source": [
        "Dont Run the cells from down here. They generate pickle files of the training data. If you already have the pickle files, ignore....\n",
        "---------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-RfCicU84Eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8bc25a-e0d9-4c62-c659-89d5dfb1203a"
      },
      "source": [
        "cd /content/gdrive/MyDrive/iSAFE/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1BtoPSFSyK0cGiJd17y7DEtIQP1Z6V3fY/iSAFE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE9cXdg-KKdX"
      },
      "source": [
        "import pandas\n",
        "anno_data = pandas.read_csv(\"labels_annotation_crop112.csv\")\n",
        "anno_data.columns = ['image', 'emotion']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_91hAu4wOm-6"
      },
      "source": [
        "def get_emotion(image_name):\n",
        "  return anno_data.loc[anno_data[\"image\"] == image_name].values[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOAmBA5tM1_W"
      },
      "source": [
        "for index, row in anno_data.iterrows():\n",
        "  print(row[\"image\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaR2n8U2QuBx"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "images = os.listdir(\"Images_FaceCroped_112\")\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for index,row in anno_data.iterrows():\n",
        "  print(index)\n",
        "  img = cv2.imread(\"Images_FaceCroped_112/\" + row[\"image\"])\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  X.append(img)\n",
        "  y.append(row[\"emotion\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuNjEiROXqUy"
      },
      "source": [
        "print(len(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXsYGK7gcCcp"
      },
      "source": [
        "for x in y:\n",
        "  print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk2FPgENcEUu"
      },
      "source": [
        "import numpy as np\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDFQ3sNvcJut"
      },
      "source": [
        "import pickle\n",
        "with open(\"/content/gdrive/MyDrive/honemo/iSAFEimgs_new.pickle\", \"wb\") as iSAFEimg:\n",
        "  pickle.dump(X, iSAFEimg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d0EU5FaBZXv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6TKYlLYcM9C"
      },
      "source": [
        "import pickle\n",
        "with open(\"/content/gdrive/MyDrive/honemo/emotionval_new.pickle\", \"wb\") as emotion:\n",
        "  pickle.dump(y, emotion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY7ROBkRdSmh"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta9Gs-NFPTXj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRRGrrwBde_C"
      },
      "source": [
        "**Will begin passing the training data to the CNN**\n",
        "Start running from here\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2q-aAf56fDg",
        "outputId": "395a5c24-3c47-4bed-ee12-aec65faaa69c"
      },
      "source": [
        "cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU-aFU3rKfOy",
        "outputId": "bc6b4fdd-7662-4088-e455-ed40ea7e5229"
      },
      "source": [
        "cd gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk6HsWtEKhWj",
        "outputId": "929427d7-86d4-49ea-dd71-0c1ddbd146c9"
      },
      "source": [
        "cd MyDrive/honemo/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/honemo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRFo_1Z-6gix",
        "outputId": "f60097e7-a893-4e62-da3b-15bde21f6c89"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "with open(\"emotionval_new.pickle\", 'rb') as emotionval:\n",
        "  emotion_data = pickle.load(emotionval)\n",
        "\n",
        "print(emotion_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 4 4 ... 4 4 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5EjrFqe7iYF"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "with open(\"iSAFEimgs_new.pickle\", 'rb') as iSAFE:\n",
        "  iSAFE_arr = pickle.load(iSAFE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "QjxmuHI7KuEn",
        "outputId": "17c45a7d-6a1a-47aa-df66-5172b9f1ce5e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(iSAFE_arr[773])\n",
        "print(emotion_data[773])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8adc9215ff53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miSAFE_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m773\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m773\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'iSAFE_arr' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjOmSb8SLMqO"
      },
      "source": [
        "# mod_im_np = []\n",
        "# for x in range(len(iSAFE_arr)):\n",
        "#   if x == 773:\n",
        "#     continue\n",
        "#   mod_im_np.append(iSAFE_arr[x])\n",
        "# mod_im_np = np.array(mod_im_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezaYb_r68TWh"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# X_train , y_train, X_test, y_test = train_test_split(mod_im_np, emotion_data, test_size=0.75)\n",
        "X_train = iSAFE_arr[0:2273]\n",
        "y_train = emotion_data[0:2273]\n",
        "\n",
        "X_val = iSAFE_arr[2273:2604]\n",
        "y_val = emotion_data[2273:2604]\n",
        "\n",
        "X_test = iSAFE_arr[2604:2975]\n",
        "y_test = emotion_data[2604:2975]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwu9zy5TPa3P"
      },
      "source": [
        "**Dont Run this cell everytime, here I am attempting to remove some images from   class  4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05A6oiVAPZGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb2b41a-b234-4af0-94eb-75db8d49f531"
      },
      "source": [
        "a = 0\n",
        "indices = []\n",
        "for index, row in anno_data.iterrows():\n",
        "  if row[\"emotion\"] == 1:\n",
        "    # print(row[\"image\"])\n",
        "    rem = [\"S001\", \"S002\", \"S003\", \"S004\", \"S005\",\"S006\",\"S007\", \"S008\",\"S009\",\"S011\", \"S012\",\"S014\", \"S015\", \"S016\", \"S022\", \"S043\", \"S038\", \"S039\", \"S044\", \"S031\", \"S032\", \"S033\", \"S022\", \"S025\", \"S026\"]\n",
        "    if row[\"image\"][0:4] in rem and index < 2273:\n",
        "      indices.append(index)\n",
        "    a += 1\n",
        "print(a)\n",
        "print(indices)\n",
        "print(len(indices))\n",
        "\n",
        "rev_X_train = []\n",
        "rev_y_train = []\n",
        "\n",
        "for im in range(len(X_train)):\n",
        "  if im not in indices:\n",
        "    rev_X_train.append(X_train[im])\n",
        "    rev_y_train.append(y_train[im])\n",
        "\n",
        "import numpy as np\n",
        "rev_X_train = np.array(rev_X_train)\n",
        "rev_y_train = np.array(rev_y_train)\n",
        "\n",
        "X_train = rev_X_train\n",
        "y_train = rev_y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "841\n",
            "[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 102, 103, 104, 105, 106, 107, 108, 109, 176, 177, 178, 179, 180, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 297, 298, 299, 370, 371, 372, 373, 374, 375, 376, 377, 378, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 454, 455, 456, 457, 458, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 617, 618, 619, 620, 621, 622, 623, 624, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 743, 744, 745, 746, 747, 748, 796, 797, 798, 799, 800, 801, 802, 803, 804, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 928, 929, 930, 931, 932, 946, 947, 948, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1579, 1580, 1581, 1582, 1583, 1584, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105]\n",
            "386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QWUHqWnRPTQ",
        "outputId": "8bec822e-4f19-49d0-e441-1274c7f459d5"
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "# print(len(mod_im_np))\n",
        "# print(len(emotion_data))\n",
        "\n",
        "# print(len(X_train))\n",
        "# print(len(y_train))\n",
        "print(len(X_test))\n",
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371\n",
            "371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w82ix11b8a6s"
      },
      "source": [
        "\n",
        "# index = 0\n",
        "# for im in images:\n",
        "#   if im == \"S001.1.1.jpg\":\n",
        "#     print(index)\n",
        "#   index += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQQBmQgWHSTj"
      },
      "source": [
        "# plt.imshow(iSAFE_arr[773])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jrIrKPLHbsu"
      },
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# img = cv2.imread(\"Images_FaceCroped_112/\" + \"S001.1.1.jpg\")\n",
        "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "# plt.imshow(img)\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# iSAFE_arr = np.delete(iSAFE_arr, 773)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FPPUUtZIVr6"
      },
      "source": [
        "# print(iSAFE_arr[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNxcdbwjMnb4"
      },
      "source": [
        "def prep_pixels(train, val, test):\n",
        "\t# convert from integers to floats\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm = test.astype('float32')\n",
        "  val_norm = val.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "  train_norm = train_norm / 255.0\n",
        "  test_norm = test_norm / 255.0\n",
        "  val_norm = val_norm / 255.0\n",
        "  # return normalized images\n",
        "  return train_norm, val_norm, test_norm\n",
        "\n",
        "X_train, X_val, X_test = prep_pixels(X_train, X_val, X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXwFr5jfOGtR",
        "outputId": "e3320bf5-99d2-4638-ac60-bc5a093e3a7d"
      },
      "source": [
        "ls checkpoints/iSAFEResnet34_3/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcp-0001.ckpt\u001b[0m/  \u001b[01;34mcp-0002.ckpt\u001b[0m/  \u001b[01;34mcp-0003.ckpt\u001b[0m/  \u001b[01;34mcp-0004.ckpt\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y4O8mmYVya7",
        "outputId": "7e63225e-4d2a-4fd7-ca91-c4775c636ad6"
      },
      "source": [
        "model.load_weights(\"checkpoints/iSAFEResnet34_rem_1_again/cp-0003.ckpt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0ce67fc410>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUGutA1KN0ae"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "import os\n",
        "\n",
        "name = \"iSAFEResnet34_learn_l2\"\n",
        "checkpoint_path = \"checkpoints/\"+name+\"/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "os.system('mkdir {}'.format(checkpoint_dir))\n",
        "\n",
        "# save model after each epoch\n",
        "cp_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1\n",
        ")\n",
        "tensorboard_callback = TensorBoard(\n",
        "    log_dir='tensorboard_logs2/'+name,\n",
        "    histogram_freq=1\n",
        ")\n",
        "\n",
        "\n",
        "# opt = SGD(lr=0.001, momentum=0.9)\n",
        "# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='loss', verbose=1,\n",
        "#     save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "# history = model.fit(X_train, y_train, epochs=2, batch_size=128, validation_data=(X_test, y_test), verbose=1, callbacks=[checkpoint])\n",
        "model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=128,\n",
        "    callbacks=[cp_callback, tensorboard_callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTI0mby853nD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3818f9-361b-46ee-953b-07723b01d6cc"
      },
      "source": [
        "opt = SGD(lr=0.2, momentum=0.8)\n",
        "model.compile(\n",
        "        optimizer=opt,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "model.load_weights(\"checkpoints/iSAFEResnet34_rem_1_again/cp-0003.ckpt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f43365ec110>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l4xufBlk6B8"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "import os\n",
        "\n",
        "name = \"iSAFEResnet34_fresh_kfold_2\"\n",
        "checkpoint_path = \"checkpoints/\"+name+\"/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "os.system('mkdir {}'.format(checkpoint_dir))\n",
        "\n",
        "# save model after each epoch\n",
        "cp_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1\n",
        ")\n",
        "tensorboard_callback = TensorBoard(\n",
        "    log_dir='tensorboard_logs2/'+name,\n",
        "    histogram_freq=1\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMI0uOm3CfSB"
      },
      "source": [
        "KFold Cross Validation Attempt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4yJ86xnCeO1",
        "outputId": "4011bd1c-96ae-4e20-8ea9-fb5ca4c4e8ae"
      },
      "source": [
        "import numpy as np\n",
        "prim_fold_init = 0\n",
        "prim_fold_final = 227\n",
        "\n",
        "\n",
        "for i in range(3, 9):\n",
        "  fold_init = prim_fold_init + 227 * i\n",
        "  fold_final = prim_fold_final + 227 * i\n",
        "  fold_X_val = X_train[fold_init:fold_final]\n",
        "  fold_y_val = y_train[fold_init:fold_final]\n",
        "  rev_X_train = np.append(X_train[0:fold_init], X_train[fold_final:], axis=0)\n",
        "  rev_y_train = np.append(y_train[0:fold_init], y_train[fold_final:], axis=0)\n",
        "  # print(rev_X_train.shape)\n",
        "  # print(rev_y_train.shape)\n",
        "  # print(len(rev_X_train), len(rev_Y_train))\n",
        "\n",
        "  model.fit(rev_X_train, rev_y_train,\n",
        "            epochs=1, \n",
        "            verbose=1, \n",
        "            validation_data=(fold_X_val, fold_y_val), \n",
        "            batch_size=128, \n",
        "            callbacks=[cp_callback, tensorboard_callback] )\n",
        "  \n",
        "\n",
        "  # print(fold_init, fold_final)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 360s 22s/step - loss: 0.0107 - accuracy: 0.9990 - val_loss: 1.4475 - val_accuracy: 0.6520\n",
            "\n",
            "Epoch 00001: saving model to checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt\n",
            "INFO:tensorflow:Assets written to: checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 357s 22s/step - loss: 0.0142 - accuracy: 0.9980 - val_loss: 1.4866 - val_accuracy: 0.7004\n",
            "\n",
            "Epoch 00001: saving model to checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt\n",
            "INFO:tensorflow:Assets written to: checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 358s 22s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.8722\n",
            "\n",
            "Epoch 00001: saving model to checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt\n",
            "INFO:tensorflow:Assets written to: checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 359s 22s/step - loss: 3.6604e-04 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.7753\n",
            "\n",
            "Epoch 00001: saving model to checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt\n",
            "INFO:tensorflow:Assets written to: checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 365s 23s/step - loss: 2.4361e-04 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9604\n",
            "\n",
            "Epoch 00001: saving model to checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt\n",
            "INFO:tensorflow:Assets written to: checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 362s 23s/step - loss: 2.4843e-04 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9339\n",
            "\n",
            "Epoch 00001: saving model to checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt\n",
            "INFO:tensorflow:Assets written to: checkpoints/iSAFEResnet34_fresh_kfold_2/cp-0001.ckpt/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PW-dVKGUU9GX",
        "outputId": "51c9deb9-fafa-4c08-9ea6-4e8c96e09600"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/honemo'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtgF9W5tP1OQ",
        "outputId": "f0e76cfb-d661-4d77-f398-fd6f812b8113"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(y_train))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2600\n",
            "2600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCQj2upyE-9G"
      },
      "source": [
        "plt.imshow(X_train[806])\n",
        "print(y_train[806])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lCqZTdGF46F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d366af87-e446-400b-f3e7-93cd1bf3c7e0"
      },
      "source": [
        "model.evaluate(X_val, y_val, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 12s 1s/step - loss: 6.4771 - accuracy: 0.2085\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.477148056030273, 0.20845921337604523]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtDfV6C5To3n"
      },
      "source": [
        "\n",
        "res = model.predict(X_test)\n",
        "\n",
        "for p in res:\n",
        "  p = list(p)\n",
        "  print(p.index(max(p)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "Yz-modr5ooDj",
        "outputId": "365eb8bb-1632-4750-c093-576366a06057"
      },
      "source": [
        "num_im = {}\n",
        "for im in y_val:\n",
        "  im = list(im)\n",
        "  im = im.index(max(im))\n",
        "  if im not in num_im.keys():\n",
        "    num_im[im] = 1\n",
        "  else:\n",
        "    num_im[im] += 1\n",
        "\n",
        "for x in range(1, len(num_im)+1):\n",
        "  print(x, num_im[x])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-128eb3aeb1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnum_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_val' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwnlYodIOSZt",
        "outputId": "a21cb127-5aca-4e33-df0b-284162a972b7"
      },
      "source": [
        "num_im = {}\n",
        "for im in y_test:\n",
        "  im = list(im)\n",
        "  im = im.index(max(im))\n",
        "  if im not in num_im.keys():\n",
        "    num_im[im] = 1\n",
        "  else:\n",
        "    num_im[im] += 1\n",
        "\n",
        "for x in range(1, len(num_im)+1):\n",
        "  print(x, num_im[x] / len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.1778975741239892\n",
            "2 0.04582210242587601\n",
            "3 0.07008086253369272\n",
            "4 0.261455525606469\n",
            "5 0.16172506738544473\n",
            "6 0.05121293800539083\n",
            "7 0.1940700808625337\n",
            "8 0.03773584905660377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qfWpyEr_T32",
        "outputId": "5b8538d1-13dd-47ad-cb9b-64d0faec8619"
      },
      "source": [
        "num_im = {}\n",
        "for im in emotion_data[0:2273]:\n",
        "  if im not in num_im.keys():\n",
        "    num_im[im] = 1\n",
        "  else:\n",
        "    num_im[im] += 1\n",
        "\n",
        "for x in range(1, len(num_im)+1):\n",
        "  print(x, num_im[x] / len(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.3375728669846317\n",
            "2 0.18018018018018017\n",
            "3 0.14626391096979333\n",
            "4 0.178060413354531\n",
            "5 0.1086380498145204\n",
            "6 0.08797032326444092\n",
            "7 0.13089560148383678\n",
            "8 0.034976152623211444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ_B4lxV1h22",
        "outputId": "35be7ee8-f924-4402-e15a-d651b4a242fc"
      },
      "source": [
        "num_im = {}\n",
        "for im in y_train:\n",
        "  # im = list(im)\n",
        "  # im = im.index(max(im))\n",
        "  if im not in num_im.keys():\n",
        "    num_im[im] = 1\n",
        "  else:\n",
        "    num_im[im] += 1\n",
        "\n",
        "for x in range(1, len(num_im)+1):\n",
        "  print(x, num_im[x] / len(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.13301536830948596\n",
            "2 0.18018018018018017\n",
            "3 0.14626391096979333\n",
            "4 0.178060413354531\n",
            "5 0.1086380498145204\n",
            "6 0.08797032326444092\n",
            "7 0.13089560148383678\n",
            "8 0.034976152623211444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn16I8oFCA7L",
        "outputId": "2aaee4cf-320c-43a5-d3fe-c284c656da38"
      },
      "source": [
        "# Figures out where the bias is \n",
        "num_im = {}\n",
        "for im in res:\n",
        "  im = list(im)\n",
        "  im = im.index(max(im))\n",
        "  if str(im) not in num_im.keys():\n",
        "    num_im[str(im)] = 1\n",
        "  else:\n",
        "    num_im[str(im)] += 1\n",
        "\n",
        "print(num_im)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'4': 141, '5': 61, '3': 23, '2': 48, '1': 42, '7': 48, '6': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pk7NOKLYQJN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkpEZy86toWb"
      },
      "source": [
        "Attempting to Test the CNN on OpenFace "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "splk-3eFtmjA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuTUxW1DPmmv"
      },
      "source": [
        "checkpoints/iSAFEResnet34_3/cp-0003.ckpt 34.77 \n"
      ]
    }
  ]
}